{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from scandataset import SCANDataset\n",
    "from scandataloader import SCANDataLoader\n",
    "from transformer import Transformer\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hyperparam_config.hyperparam_exp23 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "\n",
    "src_vocab = [\n",
    "    '<PAD>',\n",
    "    '<BOS>',\n",
    "    '<EOS>',\n",
    "    'walk',\n",
    "    'look',\n",
    "    'run',\n",
    "    'jump',\n",
    "    'turn',\n",
    "    'left',\n",
    "    'right',\n",
    "    'and',\n",
    "    'after',\n",
    "    'opposite',\n",
    "    'twice',\n",
    "    'thrice',\n",
    "    'around',\n",
    "]\n",
    "\n",
    "tgt_vocab = [\n",
    "    '<PAD>',\n",
    "    '<BOS>',\n",
    "    '<EOS>',\n",
    "    'I_WALK',\n",
    "    'I_RUN',\n",
    "    'I_JUMP',\n",
    "    'I_LOOK',\n",
    "    'I_TURN_RIGHT',\n",
    "    'I_TURN_LEFT'\n",
    "]\n",
    "\n",
    "def list_to_dict(lst):\n",
    "    return {k: v for v, k in enumerate(lst)}\n",
    "\n",
    "src_vocab = list_to_dict(src_vocab)\n",
    "tgt_vocab = list_to_dict(tgt_vocab)\n",
    "\n",
    "scandataloader = SCANDataLoader()\n",
    "data = []\n",
    "\n",
    "data.append((\n",
    "    scandataloader.load_file_path(\n",
    "        os.path.join('data', 'add_prim_split', f'tasks_train_addprim_turn_left.txt')\n",
    "    ),\n",
    "    scandataloader.load_file_path(\n",
    "        os.path.join('data', 'add_prim_split', f'tasks_test_addprim_turn_left.txt')\n",
    "    )\n",
    "))\n",
    "\n",
    "data.append((\n",
    "    scandataloader.load_file_path(\n",
    "        os.path.join('data', 'add_prim_split', f'tasks_train_addprim_jump.txt')\n",
    "    ),\n",
    "    scandataloader.load_file_path(\n",
    "        os.path.join('data', 'add_prim_split', f'tasks_test_addprim_jump.txt')\n",
    "    )\n",
    "))\n",
    "\n",
    "for exponent in range(6):\n",
    "    pow2 = 2**exponent\n",
    "    train_paths = []\n",
    "    test_paths = []\n",
    "    for i in range(1, 5):\n",
    "        train_paths.append((os.path.join(\n",
    "            'data', \n",
    "            'add_prim_split', \n",
    "            'with_additional_examples',\n",
    "            f'tasks_train_addprim_complex_jump_num{pow2}_rep{i}.txt'\n",
    "        )))\n",
    "        test_paths.append((os.path.join(\n",
    "            'data', \n",
    "            'add_prim_split', \n",
    "            'with_additional_examples',\n",
    "            f'tasks_test_addprim_complex_jump_num{pow2}_rep{i}.txt'\n",
    "        )))\n",
    "    data.append((\n",
    "        scandataloader.load_file_paths(train_paths),\n",
    "        scandataloader.load_file_paths(test_paths)\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, criterion, dataloader, epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            src = batch['src'].to(device)\n",
    "            tgt = batch['tgt'].to(device)\n",
    "\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "\n",
    "            output = model(src, tgt_input)\n",
    "            \n",
    "            output = output.view(-1, output.shape[-1])\n",
    "            tgt_output = tgt_output.reshape(-1)\n",
    "\n",
    "            loss = criterion(output, tgt_output)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    special_tokens = [tgt_vocab['<PAD>'], tgt_vocab['<BOS>'], tgt_vocab['<EOS>']]\n",
    "\n",
    "    start_token = tgt_vocab['<BOS>']\n",
    "    end_token = tgt_vocab['<EOS>']\n",
    "\n",
    "    total_tokens = 0\n",
    "    correct_tokens = 0\n",
    "    total_seq = 0\n",
    "    correct_seq = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            src = batch['src'].to(device)\n",
    "            tgt = batch['tgt'].to(device)\n",
    "\n",
    "            output = model.predict(src, start_token, end_token, MAX_LEN)\n",
    "\n",
    "            for i in range(output.size(0)):\n",
    "                tgt_tokens = tgt[i].cpu().numpy()\n",
    "                pred_tokens = output[i].cpu().numpy()\n",
    "\n",
    "                for t, p in zip(tgt_tokens, pred_tokens):\n",
    "                    if t not in special_tokens:\n",
    "                        total_tokens += 1\n",
    "                        if t == p:\n",
    "                            correct_tokens += 1\n",
    "\n",
    "                if all(t == p for t, p in zip(tgt_tokens, pred_tokens) if t not in special_tokens):\n",
    "                    correct_seq += 1\n",
    "                total_seq += 1\n",
    "\n",
    "    token_accuracy = correct_tokens / total_tokens\n",
    "    seq_accuracy = correct_seq / total_seq\n",
    "\n",
    "    return token_accuracy, seq_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:09<01:09, 69.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:23<00:00, 71.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.1281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-level accuracy: 0.7668607254814152, Sequence-level accuracy: 0.5695364238410596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:51<00:51, 51.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:44<00:00, 52.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.2696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-level accuracy: 0.6103454620324698, Sequence-level accuracy: 0.0018167661562418895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [02:57<02:57, 177.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [05:51<00:00, 175.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-level accuracy: 0.8023745892661556, Sequence-level accuracy: 0.372485399091499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [02:54<02:54, 174.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [05:50<00:00, 175.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 8\n",
    "epochs = 2\n",
    "token_accuracies = []\n",
    "seq_accuracies = []\n",
    "\n",
    "for i in range(N):\n",
    "    train_data, test_data = data[i]\n",
    "\n",
    "    dataset_train = SCANDataset(\n",
    "        data=train_data,\n",
    "        src_vocab=src_vocab,\n",
    "        tgt_vocab=tgt_vocab,\n",
    "        max_len=MAX_LEN,\n",
    "    )\n",
    "\n",
    "    dataset_test = SCANDataset(\n",
    "        data=test_data,\n",
    "        src_vocab=src_vocab,\n",
    "        tgt_vocab=tgt_vocab,\n",
    "        max_len=MAX_LEN,\n",
    "    )\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "    model = Transformer(\n",
    "        src_vocab_size=len(src_vocab),\n",
    "        tgt_vocab_size=len(tgt_vocab),\n",
    "        src_pad_idx=src_vocab['<PAD>'],\n",
    "        tgt_pad_idx=tgt_vocab['<PAD>'],\n",
    "        emb_dim=EMB_DIM,\n",
    "        num_layers=N_LAYERS,\n",
    "        num_heads=N_HEADS,\n",
    "        forward_dim=FORWARD_DIM,\n",
    "        dropout=DROPOUT,\n",
    "        max_len=MAX_LEN,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab['<PAD>'])\n",
    "\n",
    "    train_loop(model, optimizer, criterion, dataloader_train, epochs)\n",
    "\n",
    "    token_accuracy, seq_accuracy = eval_loop(model, dataloader_test)\n",
    "\n",
    "    print(f'Token-level accuracy: {token_accuracy}, Sequence-level accuracy: {seq_accuracy}')\n",
    "\n",
    "    if i > 0:\n",
    "        token_accuracies.append(token_accuracy * 100)\n",
    "        seq_accuracies.append(seq_accuracy * 100)\n",
    "\n",
    "X = ['0', '1', '2', '4', '8', '16', '32']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].bar(X, token_accuracies, color='royalblue')\n",
    "axes[0].ylim(0, 110)\n",
    "axes[0].set_title(\"Token-Level Accuracy\")\n",
    "axes[0].set_xlabel(\"Number of Composed Commands Used For Training\")\n",
    "axes[0].set_ylabel(\"Accuracy on new commands (%)\")\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "axes[1].bar(X, seq_accuracies, color='royalblue')\n",
    "axes[1].ylim(0, 110)\n",
    "axes[1].set_title(\"Sequence-Level Accuracy\")\n",
    "axes[1].set_xlabel(\"Number of Composed Commands Used For Training\")\n",
    "axes[1].set_ylabel(\"Accuracy on New Commands (%)\")\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
